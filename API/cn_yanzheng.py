import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
import time
import os
import json

# å…¨å±€é…ç½®
BASE_DIR = 'output/diqu'
CN_FILE = os.path.join(BASE_DIR, 'cn.txt')
HTTP_PLUS = os.path.join(BASE_DIR, 'cn_http_90+.txt')
HTTP_MINUS = os.path.join(BASE_DIR, 'cn_http_90-.txt')
HTTPS_PLUS = os.path.join(BASE_DIR, 'cn_https_90+.txt')
HTTPS_MINUS = os.path.join(BASE_DIR, 'cn_https_90-.txt')
CHECK_URLS = {
    'http': 'http://httpbin.org/ip',
    'https': 'https://httpbin.org/ip'  # HTTPSéªŒè¯åœ°å€
}
TIMEOUT = 5
THREADS = 100
CHECK_INTERVAL = 10
MIN_CHECKS = 10

# å…¨å±€çŠ¶æ€è·Ÿè¸ª
proxy_history = {}

def load_proxies():
    """åŠ è½½å¹¶å»é‡ä»£ç†åˆ—è¡¨"""
    try:
        with open(CN_FILE, 'r') as f:
            return list({line.strip() for line in f if line.strip()})
    except Exception as e:
        print(f"âš ï¸ ä»£ç†åŠ è½½é”™è¯¯: {str(e)}")
        return []

def verify_proxy(proxy):
    """åŒåè®®éªŒè¯å‡½æ•°"""
    results = {'http': False, 'https': False}
    
    # éªŒè¯HTTP
    try:
        response = requests.get(
            CHECK_URLS['http'],
            proxies={'http': f'http://{proxy}'},
            timeout=TIMEOUT,
            headers={'User-Agent': 'Mozilla/5.0'}
        )
        if response.status_code == 200:
            origin_ip = json.loads(response.text).get('origin', '')
            proxy_ip = proxy.split(':')[0]
            results['http'] = (origin_ip == proxy_ip)
    except:
        pass
    
    # éªŒè¯HTTPS
    try:
        response = requests.get(
            CHECK_URLS['https'],
            proxies={'https': f'http://{proxy}'},  # æ³¨æ„è¿™é‡Œä½¿ç”¨httpåè®®è¿æ¥HTTPSä»£ç†
            timeout=TIMEOUT,
            headers={'User-Agent': 'Mozilla/5.0'}
        )
        if response.status_code == 200:
            origin_ip = json.loads(response.text).get('origin', '')
            proxy_ip = proxy.split(':')[0]
            results['https'] = (origin_ip == proxy_ip)
    except:
        pass
    
    return (proxy, results['http'], results['https'])

def update_classification(protocol):
    """æ›´æ–°æŒ‡å®šåè®®çš„åˆ†ç±»æ–‡ä»¶"""
    plus_file = HTTP_PLUS if protocol == 'http' else HTTPS_PLUS
    minus_file = HTTP_MINUS if protocol == 'http' else HTTPS_MINUS
    
    valid_proxies = []
    invalid_proxies = []
    
    # éå†æ‰€æœ‰å·²çŸ¥ä»£ç†
    for proxy in proxy_history:
        stats = proxy_history[proxy].get(protocol, {'success': 0, 'total': 0})
        if stats['total'] >= MIN_CHECKS:
            survival_rate = (stats['success'] / stats['total']) * 100
            if survival_rate >= 90:
                valid_proxies.append(proxy)
            else:
                invalid_proxies.append(proxy)
    
    # å†™å…¥æ–‡ä»¶
    with open(plus_file, 'w') as f:
        f.write('\n'.join(valid_proxies))
    with open(minus_file, 'w') as f:
        f.write('\n'.join(invalid_proxies))
    
    return len(valid_proxies), len(invalid_proxies)

def main():
    verification_round = 0
    os.makedirs(BASE_DIR, exist_ok=True)

    while True:
        verification_round += 1
        current_proxies = load_proxies()
        
        if not current_proxies:
            print(f"â³ è½®æ¬¡ {verification_round}: æ— å¯ç”¨ä»£ç†ï¼Œè·³è¿‡éªŒè¯")
            time.sleep(CHECK_INTERVAL)
            continue
        
        # å¤šçº¿ç¨‹éªŒè¯
        print(f"\nğŸ” è½®æ¬¡ {verification_round} éªŒè¯ {len(current_proxies)} ä¸ªä»£ç†")
        results = []
        with ThreadPoolExecutor(max_workers=THREADS) as executor:
            futures = [executor.submit(verify_proxy, p) for p in current_proxies]
            with tqdm(total=len(futures), desc="éªŒè¯è¿›åº¦", unit="proxy") as pbar:
                for future in as_completed(futures):
                    proxy, http_valid, https_valid = future.result()
                    results.append((proxy, http_valid, https_valid))
                    pbar.update(1)
        
        # æ›´æ–°å†å²è®°å½•
        for proxy, http_valid, https_valid in results:
            if proxy not in proxy_history:
                proxy_history[proxy] = {
                    'http': {'success': 0, 'total': 0},
                    'https': {'success': 0, 'total': 0}
                }
            
            # æ›´æ–°HTTPç»Ÿè®¡
            proxy_history[proxy]['http']['total'] += 1
            proxy_history[proxy]['http']['success'] += int(http_valid)
            
            # æ›´æ–°HTTPSç»Ÿè®¡
            proxy_history[proxy]['https']['total'] += 1
            proxy_history[proxy]['https']['success'] += int(https_valid)
        
        # å­˜æ´»ç‡åˆ†ç±»ï¼ˆä»ç¬¬10æ¬¡éªŒè¯å¼€å§‹ï¼‰
        if verification_round >= 10:
            http_valid_count, http_invalid_count = update_classification('http')
            https_valid_count, https_invalid_count = update_classification('https')
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            current_http_success = sum(1 for _, h, _ in results if h)
            current_https_success = sum(1 for _, _, h in results if h)
            print(f"\nğŸ“Š éªŒè¯ç»Ÿè®¡ï¼š")
            print(f"HTTP æœ¬æ¬¡æˆåŠŸç‡: {current_http_success}/{len(results)} ({current_http_success/len(results):.1%})")
            print(f"HTTPS æœ¬æ¬¡æˆåŠŸç‡: {current_https_success}/{len(results)} ({current_https_success/len(results):.1%})")
            print(f"HTTP å†å²åˆ†ç±»: {http_valid_count} æœ‰æ•ˆ | {http_invalid_count} æ— æ•ˆ")
            print(f"HTTPS å†å²åˆ†ç±»: {https_valid_count} æœ‰æ•ˆ | {https_invalid_count} æ— æ•ˆ")
            print(f"æ–‡ä»¶è·¯å¾„ï¼š\n- HTTP: {HTTP_PLUS}\n- HTTPS: {HTTPS_PLUS}")

        # ç­‰å¾…ä¸‹ä¸€è½®
        print(f"\nâ²ï¸ ä¸‹æ¬¡éªŒè¯ {time.strftime('%H:%M:%S', time.localtime(time.time()+CHECK_INTERVAL))}")
        time.sleep(CHECK_INTERVAL)

if __name__ == "__main__":
    main()